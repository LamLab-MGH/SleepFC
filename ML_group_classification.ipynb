{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hx4ae9iDhq7"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3O08nnXE6RL"
   },
   "outputs": [],
   "source": [
    "def ml_classifier(input_table, target, n_iterations):\n",
    "    \"\"\"\n",
    "    Train an XGBoost classifier using Leave-One-Out cross-validation and obtain test-set results\n",
    "    via bootstrap.\n",
    "\n",
    "    Args:\n",
    "        input_table (pd.DataFrame): Input dataset containing features and class labels.\n",
    "        target (string): Column to predict.\n",
    "        n_iterations (int): Number of bootstrap iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the AUC, FPR, TPR, thresholds, and feature importances for each iteration.\n",
    "    \"\"\"\n",
    "    # Bootstrap 90% of the sample size each time\n",
    "    np.random.seed(42)\n",
    "    n_size = int(len(input_table) * 0.9)\n",
    "\n",
    "    # Initialize variables\n",
    "    stats = list()\n",
    "    metrics = ['auc', 'fpr', 'tpr', 'thresholds', 'feature_importances']\n",
    "    results = {'main': {m: [] for m in metrics}}\n",
    "\n",
    "    # Loop through subsamples\n",
    "    for i in tqdm(range(n_iterations), desc=\"Bootstrap iterations\"):\n",
    "        # Get subsamples\n",
    "        subsampled_data = resample(input_table, n_samples=n_size, stratify=input_table[target].values)\n",
    "        y = subsampled_data[target].values\n",
    "        X = subsampled_data.drop(columns=[target]).values\n",
    "\n",
    "        loo = LeaveOneOut()\n",
    "        loo.get_n_splits(X)\n",
    "\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "        importances = []\n",
    "\n",
    "        for train_index, test_index in loo.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            clf = xgb.XGBClassifier()\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            labels.append(y_test)\n",
    "            probabilities.append(clf.predict_proba(X_test)[:, 1])\n",
    "            importances.append(clf.feature_importances_)\n",
    "\n",
    "        stats.append(roc_auc_score(labels, probabilities))\n",
    "        fpr, tpr, thresholds = roc_curve(labels, probabilities)\n",
    "        results['main']['fpr'].append(fpr)\n",
    "        results['main']['tpr'].append(tpr)\n",
    "        results['main']['thresholds'].append(thresholds)\n",
    "        results['main']['auc'].append(roc_auc_score(labels, probabilities))\n",
    "        results['main']['feature_importances'].append(np.mean(importances, axis=0))\n",
    "\n",
    "    return results\n",
    "\n",
    "def plot_roc_all_features(results, n_iterations):\n",
    "    \"\"\"\n",
    "    This function creates and plots a ROC for a classifier's performance using all features.\n",
    "\n",
    "    Args:\n",
    "    results (dict): A dictionary containing the results of the classifier, including 'fpr', 'tpr', and 'auc' keys.\n",
    "    n_iterations (int): The number of iterations used for creating the interpolated TPR values.\n",
    "\n",
    "    Returns:\n",
    "    None: The function saves the ROC plot as an image file and displays it.\n",
    "    \"\"\"\n",
    "    # Set plot parameters\n",
    "    colors = {\n",
    "        'filla': 'rgba(52, 152, 219, 0.2)',\n",
    "        'linea': 'rgba(52, 152, 219, 0.5)',\n",
    "        'maina': 'rgba(41, 128, 185, 1.0)',\n",
    "        'grid': 'rgba(189, 195, 199, 0.5)',\n",
    "        'annot': 'rgba(149, 165, 166, 0.5)',\n",
    "        'highlight': 'rgba(192, 57, 43, 1.0)'\n",
    "    }\n",
    "\n",
    "    fpr_mean = np.linspace(0, 1, n_iterations)\n",
    "    interp_tprs = []\n",
    "\n",
    "    # Calculate confidence bands\n",
    "    for i in range(n_iterations):\n",
    "        fpr, tpr = results['main']['fpr'][i], results['main']['tpr'][i]\n",
    "        interp_tprs.append(np.interp(fpr_mean, fpr, tpr))\n",
    "        interp_tprs[-1][0] = 0.0\n",
    "\n",
    "    tpr_mean = np.mean(interp_tprs, axis=0)\n",
    "    tpr_mean[-1] = 1.0\n",
    "\n",
    "    tpr_ci = np.std(interp_tprs, axis=0) * 1.96\n",
    "    tpr_upper = np.clip(tpr_mean + tpr_ci, 0, 1)\n",
    "    tpr_lower = tpr_mean - tpr_ci\n",
    "\n",
    "    auc = np.mean(results['main']['auc'])\n",
    "\n",
    "    plot_data = [\n",
    "        go.Scatter(x=fpr_mean, y=tpr_upper, line=dict(color=colors['linea'], width=1), hoverinfo=\"skip\", showlegend=False, name='upper'),\n",
    "        go.Scatter(x=fpr_mean, y=tpr_lower, fill='tonexty', fillcolor=colors['filla'], line=dict(color=colors['linea'], width=1), hoverinfo=\"skip\", showlegend=False, name='lower'),\n",
    "        go.Scatter(x=fpr_mean, y=tpr_mean, line=dict(color=colors['maina'], width=2), hoverinfo=\"skip\", showlegend=True, name=f'AUC = {auc:.3f} [{tpr_lower.mean():.3f} {tpr_upper.mean():.3f}]')\n",
    "    ]\n",
    "\n",
    "    fig = go.Figure(plot_data)\n",
    "    fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        title_x=0.5,\n",
    "        xaxis_title=\"1 - Specificity\",\n",
    "        yaxis_title=\"Sensitivity\",\n",
    "        width=600,\n",
    "        height=600,\n",
    "        legend=dict(yanchor=\"bottom\", xanchor=\"right\", x=0.95, y=0.01),\n",
    "        font=dict(family=\"Arial\", size=22, color=\"black\")\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1], gridcolor=colors['grid'], scaleanchor=\"x\", scaleratio=1, linecolor='black')\n",
    "    fig.update_xaxes(range=[0, 1], gridcolor=colors['grid'], constrain='domain', linecolor='black')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_feature_importances(results, input_table, target):\n",
    "    \"\"\"\n",
    "    Plot the feature importances based on the output of ml_classifier using a horizontal bar plot.\n",
    "\n",
    "    Args:\n",
    "        results (dict): The results dictionary from ml_classifier.\n",
    "        input_table (pd.DataFrame): Input dataset.\n",
    "        target (string): Target column.\n",
    "\n",
    "    Returns:\n",
    "        None: Shows the feature importance plot.\n",
    "    \"\"\"\n",
    "\n",
    "    # Correctly access 'feature_importances' from the nested dictionary structure\n",
    "    feature_importance_mean = np.mean(results['main']['feature_importances'], axis=0)\n",
    "    feature_importance_std = np.std(results['main']['feature_importances'], axis=0)\n",
    "\n",
    "    # Calculate SEM\n",
    "    n = len(results['main']['feature_importances'])\n",
    "    sem = feature_importance_std / np.sqrt(n)\n",
    "\n",
    "    # Get feature names\n",
    "    feature_names = input_table.drop(columns=[target]).columns.tolist()\n",
    "\n",
    "    # Remove \"_\" characters from feature names\n",
    "    feature_names = [name.replace(\"_\", \"-\") for name in feature_names]\n",
    "\n",
    "    # Sorting the features by importance in ascending order\n",
    "    sorted_idx = feature_importance_mean.argsort()\n",
    "    feature_importance_mean = feature_importance_mean[sorted_idx]\n",
    "    sem = sem[sorted_idx]\n",
    "    feature_names_sorted = [feature_names[i] for i in sorted_idx]\n",
    "\n",
    "    # Create a horizontal bar plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # We use y-axis for feature names and x-axis for feature importance values in horizontal bar plots\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=feature_names_sorted,\n",
    "            x=feature_importance_mean,\n",
    "            orientation='h',\n",
    "            error_x=dict(type='data', array=sem, visible=True)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Layout configuration\n",
    "    fig.update_layout(\n",
    "        # title=\"Feature Importances with SEM\",\n",
    "        xaxis_title=\"Feature Importance\",\n",
    "        yaxis_title=\"Features\",\n",
    "        template='plotly_white',\n",
    "        width=600,\n",
    "        height=600,\n",
    "        font=dict(family=\"Arial\", size=22, color=\"black\")\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1tLW8dojyeJE",
    "outputId": "496f037d-4018-4bff-9018-6d4fdca5b491"
   },
   "outputs": [],
   "source": [
    "# Load the CSV file of the features of interest without NaNs\n",
    "groups_input = pd.read_csv('./Group_features.csv', index_col = 0)\n",
    "groups_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "aGIiZFjKhN4S",
    "outputId": "9a6f865d-59da-4b0e-ea1c-1be5bec241bc"
   },
   "outputs": [],
   "source": [
    "# Drop the unnecesary columns\n",
    "groups_input = groups_input.drop('ID', axis=1)\n",
    "groups_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "5QesWTo1mDXj",
    "outputId": "54061e2f-bca0-4492-ee6d-3bd4e44ca792"
   },
   "outputs": [],
   "source": [
    "# Select the groups to be compared and change the class names to integers\n",
    "filtered_df = groups_input.loc[groups_input['Class'].isin(['ADNoEp', 'HC'])].replace({'ADNoEp': 1, 'HC': 0})\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ui_4omCmC8mk",
    "outputId": "69ac21e4-9e58-49d9-b512-c65bd36c4850"
   },
   "outputs": [],
   "source": [
    "# Number of iterations for bootstrap\n",
    "n_iterations = 1000\n",
    "\n",
    "results_adnoep_hc = ml_classifier(filtered_df, \"Class\", n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "xjNInErjFcVj",
    "outputId": "a668a4c9-71dc-4c33-f9bc-594683739129"
   },
   "outputs": [],
   "source": [
    "plot_roc_all_features(results_adnoep_hc, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "AW00ktABMw1F",
    "outputId": "26602bf6-7334-4f25-8f61-3fd90bc21ef0"
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(results_adnoep_hc, filtered_df, \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4uBj8KS1nqq8",
    "outputId": "1f19ddb1-385a-4c25-c650-1e40348dd3ec"
   },
   "outputs": [],
   "source": [
    "filtered_df = groups_input.loc[groups_input['Class'].isin(['ADNoEp', 'ADEp'])].replace({'ADEp': 1, 'ADNoEp': 0})\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fw9pb2j9ttvN",
    "outputId": "22caaacd-818e-465f-8e92-14cc2f213a56"
   },
   "outputs": [],
   "source": [
    "# Number of iterations for bootstrap\n",
    "n_iterations = 1000\n",
    "\n",
    "results_adnoep_adep = ml_classifier(filtered_df, \"Class\", n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "A-Rk8uktt4Nf",
    "outputId": "0ba115e4-1834-4fe0-bc9e-702ec6c009c9"
   },
   "outputs": [],
   "source": [
    "plot_roc_all_features(results_adnoep_adep, n_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "BmF-Zsb2t7GO",
    "outputId": "29d7ca1b-77b9-4c71-934b-190f5e3d9683"
   },
   "outputs": [],
   "source": [
    "plot_feature_importances(results_adnoep_adep, filtered_df, \"Class\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
